{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-16T21:58:31.018189Z",
     "end_time": "2023-06-16T21:58:31.847745Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "import spacy\n",
    "\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../transcripts/mrs-r.csv\")\n",
    "\n",
    "df = df[df[\"Transcript\"].str.startswith(\"Mrs\")]\n",
    "df[\"Transcript\"] = df[\"Transcript\"].apply(lambda x: re.sub(r\"Mrs\\.?\\s*R\\:?\\s*\", \"\", x))\n",
    "df[\"Transcript\"] = df[\"Transcript\"].apply(lambda x: contractions.fix(x))\n",
    "df[\"Transcript\"] = df[\"Transcript\"].apply(lambda x: x.lower())\n",
    "\n",
    "transcript = \" \".join(df[\"Transcript\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T22:04:55.524540Z",
     "end_time": "2023-06-16T22:04:55.536370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # tagger, (dependency) parser, ner\n",
    "doc = nlp(transcript)\n",
    "# print(nlp.pipe_names)\n",
    "\n",
    "sentences = pd.Series([s.text for s in doc.sents])\n",
    "# sentences = [s for s in doc.sents]\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab) # vocabulary object shared with the documents the matcher will operate on\n",
    "pronouns = [\"i\", \"me\", \"mine\", \"myself\"]\n",
    "patterns = [nlp(t) for t in pronouns]\n",
    "matcher.add(\"FIRST PERSON PRONOUNS\", patterns) # add key and list of Doc objects of the pattern\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "first_person_sentences = []\n",
    "\n",
    "for sent in doc.sents:\n",
    "    for match_id, start, end in matcher(nlp(sent.text)):\n",
    "        if nlp.vocab.strings[match_id] == \"FIRST PERSON PRONOUNS\":\n",
    "            first_person_sentences.append(sent.text)\n",
    "\n",
    "# print(nlp.vocab.strings[5581825994029504612]) # maps to FIRST PERSON PRONOUNS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T22:25:11.168396Z",
     "end_time": "2023-06-16T22:25:15.631020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['first of all, i still have a strong voice at the age of 90, so a lot of people on the phone do not think i am 90, but this year i am 90 and i have lived in santa clara valley, which is now called silicon valley, oh, most of my life.',\n 'first of all, i still have a strong voice at the age of 90, so a lot of people on the phone do not think i am 90, but this year i am 90 and i have lived in santa clara valley, which is now called silicon valley, oh, most of my life.',\n 'first of all, i still have a strong voice at the age of 90, so a lot of people on the phone do not think i am 90, but this year i am 90 and i have lived in santa clara valley, which is now called silicon valley, oh, most of my life.',\n 'first of all, i still have a strong voice at the age of 90, so a lot of people on the phone do not think i am 90, but this year i am 90 and i have lived in santa clara valley, which is now called silicon valley, oh, most of my life.',\n 'so that is where i grew up',\n ', i grew up in a town of santa clara, which was right next to san jose, and it was a town of 5,000 people at the time.',\n 'so that is me.',\n 'you know something, i do not think i would take you up on that.',\n 'you know something, i do not think i would take you up on that.',\n 'so, um, i think my childhood was very, very happy.']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_person_sentences[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T22:26:34.775622Z",
     "end_time": "2023-06-16T22:26:34.791334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['i love tapioca pudding and i have not made it for a long time.',\n 'and i would have taken airplane flights, but they were not available when i was that age.',\n 'so i think the things we can create are just very, very important.',\n 'having a large family, so we ended up having a large family, and now i have a lot of my daughters and my sons.',\n 'i had wonderful times raising our children.',\n 'so , i guess he became the attorney',\n 'i was, i was born 1930, so just before the second world war started.',\n 'in fact, a couple came over yesterday and brought me some of the couple slices of her bread.',\n 'so i think getting, having time to grow up and be kids is very, very important.',\n 'it is a very simple way of looking at life and every, every day i think about one of the agreements about how it is affecting me and how i can interact with other people with more kindness and listening.',\n 'and i was bored.',\n 'what actually happened to me, i, when i started working, i told my husband, i am taking out a savings account at the bank just for my money, because when i get enough of it, i am going to take you on a trip.',\n 'and looking back, it was just a miracle that i found a man who had that kind of a good, positive attitude.',\n ', i think i enjoyed what i did better.',\n 'every day when i get up to worry, worry, worry.',\n 'well, i like to make things.',\n 'well, i always wanted to be an attorney.',\n 'so i got a job as an aide with another teacher for $5 an hour and was not a lot of money, but it was quite a while ago',\n 'so that is me.',\n 'you know something, i do not think i would take you up on that.']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(first_person_sentences))[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T22:26:49.139691Z",
     "end_time": "2023-06-16T22:26:49.144643Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"OBAMA\", [nlp(\"Barack Obama\")])\n",
    "doc = nlp(\"Barack Obama lifts America one last time in emotional farewell\")\n",
    "matches = matcher(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T21:59:13.477741Z",
     "end_time": "2023-06-16T21:59:14.059897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[(7732777389095836264, 0, 2)]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T21:59:17.156144Z",
     "end_time": "2023-06-16T21:59:17.160910Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
